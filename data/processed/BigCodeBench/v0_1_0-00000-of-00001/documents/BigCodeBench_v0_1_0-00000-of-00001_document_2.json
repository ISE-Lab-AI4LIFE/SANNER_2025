{
  "id": "BigCodeBench_v0_1_0-00000-of-00001_document_2",
  "text": "    datetimes = [\n        datetime.fromtimestamp(timestamp, pytz.timezone(tz)).strftime(DATE_FORMAT)\n        for tz in TIMEZONES\n    ]\n    df = pd.DataFrame({\"Timezone\": TIMEZONES, \"Datetime\": datetimes})\n    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"])\n    ax = df.plot.bar(x=\"Timezone\", y=\"Datetime\", legend=False)\n    plt.ylabel(\"Timezone\")\n    plt.ylabel(\"Datetime\")\n    plt.title(\"Datetime = f(Timezone)\")\n    plt.close()\n    return df, ax [DOC_SEP]     # Filter the DataFrame based on given conditions\n    selected_df = df[(df[\"Age\"] > age) & (df[\"Height\"] < height)].copy()\n\n    # Apply KMeans clustering only if there are at least 3 rows in the filtered data\n    if len(selected_df) >= 3:\n        kmeans = KMeans(n_clusters=3)\n        selected_df[\"Cluster\"] = kmeans.fit_predict(selected_df[[\"Age\", \"Height\"]])\n\n        # Visualize the clusters\n        plt.figure(figsize=(10, 5))\n        plt.scatter(selected_df[\"Age\"], selected_df[\"Height\"], c=selected_df[\"Cluster\"])\n        plt.xlabel(\"Age\")\n        plt.ylabel(\"Height\")\n        plt.title(\"KMeans Clustering based on Age and Height\")\n        ax = plt.gca()\n        return selected_df, ax\n    else:\n        selected_df[\"Cluster\"] = 0\n        return selected_df, None [DOC_SEP]     words = re.findall(r\"\\b\\w+\\b\", text.lower())\n    words = [word for word in words if word not in STOPWORDS]\n    word_counts = pd.Series(words).value_counts().rename(None)\n    return word_counts [DOC_SEP]     pattern = r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\"\n    matches = re.findall(pattern, text)\n    data = []\n    for match in matches:\n        data.append(match[:-1])\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n    df[\"Age\"] = df[\"Age\"].astype(int)\n    sns.histplot(data=df, x=\"Age\")\n    plt.show()\n    return df [DOC_SEP]     sentences = re.split(r\"\\.\\s*\", text)\n    sentences = [sentence for sentence in sentences if len(sentence.strip()) != 0]\n    vectorizer = CountVectorizer()\n    dtm = vectorizer.fit_transform(sentences)\n    df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n    return df [DOC_SEP]     sentences = re.split(r\"\\.\\s*\", text)\n    sentence_counts = {}\n\n    for i, sentence in enumerate(sentences):\n        if sentence.strip() == \"\":\n            continue\n        words = re.split(r\"\\s+\", sentence.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        sentence_counts[f\"Sentence {i+1}\"] = len(words)\n\n    sentence_counts = pd.Series(sentence_counts)\n    return sentence_counts [DOC_SEP]     pattern = r\"Score: (.*?), Category: (.*?)(\\n|$)\"\n    matches = re.findall(pattern, text)\n    data = [\n        match[:2] for match in matches\n    ]  # Extracting only the score and category from each match\n    df = pd.DataFrame(data, columns=[\"Score\", \"Category\"])\n    df[\"Score\"] = df[\"Score\"].astype(int)\n    return df [DOC_SEP]     data = pd.read_csv(csv_file_path)\n    corr = data.corr().round(2)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, cmap='coolwarm', cbar=True)\n    plt.title(title)\n    return corr, plt.gca() [DOC_SEP]     samples = np.random.normal(mu, sigma, num_samples)\n    fig, ax = plt.subplots()\n    ax.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = stats.norm.pdf(x, mu, sigma)\n    ax.plot(x, p, 'k', linewidth=2)\n\n    ax.set_title('Normal Distribution')\n    plt.show()\n    return fig [DOC_SEP]     try:\n        text = wikipedia.page(page_title).content\n    except Exception as e:\n        print(f\"An error occured: {e}\")\n        return None\n    wordcloud = WordCloud().generate(text)\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    ax = plt.gca()\n    return ax [DOC_SEP]     # Save to CSV\n    df = pd.DataFrame(result)\n    df.to_csv(csv_file_path, index=False)\n\n    # Save to JSON\n    with open(json_file_path, 'w') as f:\n        json.dump(result, f, indent=4)\n\n    return None [DOC_SEP]     # Extract the 'from_user' values\n    from_user_values = [d['from_user'] for d in result if 'from_user' in d]\n\n    # Calculate the square roots\n    square_roots = np.round(np.sqrt(from_user_values), 2)\n\n    # Plot the square root function\n    plt.figure()\n    plt.plot(from_user_values, square_roots)\n    plt.title(PLOT_TITLE)\n    plt.xlabel(X_LABEL)\n    plt.ylabel(Y_LABEL)\n\n    # Annotate the plot with the current date and time\n    now = datetime.now()\n    now_str = now.strftime(TIME_FORMAT)\n    plt.annotate(now_str, (0.05, 0.95), xycoords='axes fraction')\n    ax = plt.gca()\n    return square_roots, ax [DOC_SEP]     from_user_values = [d['from_user'] for d in result if 'from_user' in d]\n    color = random.choice(colors)\n    plt.figure()\n    sns.histplot(from_user_values, color=color)\n    plt.show() [DOC_SEP]     car_data = list(car_dict.items())\n    df = pd.DataFrame(car_data, columns=['Car', 'Color'])\n    # Create the bar chart visualization\n    color_counts = df[\"Color\"].value_counts()\n\n    figure = plt.figure()\n    # creating the bar plot\n    plt.bar(color_counts.keys(), color_counts.values, color=\"maroon\", width=0.4)\n\n    plt.xlabel(\"Color\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Distribution of Vehicle Colors\")\n    plt.show()\n    ax = plt.gca()\n\n    return df, ax [DOC_SEP]     df = pd.DataFrame(data, columns=COLUMNS)\n    analyzed_df = df.groupby(COLUMNS[:-1])[COLUMNS[-1]].nunique().reset_index()\n    analyzed_df = analyzed_df.pivot(index=COLUMNS[0], columns=COLUMNS[1], values=COLUMNS[2])\n    ax = sns.heatmap(analyzed_df, annot=True)\n    plt.show()\n    return analyzed_df, ax [DOC_SEP]     df = pd.DataFrame(data, columns=COLUMNS)\n    analyzed_df = df.groupby(COLUMNS[:-1])[COLUMNS[-1]].nunique().reset_index()\n\n    # Adjusting the plotting logic\n    fig, ax = plt.subplots()\n    ax.plot(analyzed_df[COLUMNS[:-1]].astype(str).agg('-'.join, axis=1), analyzed_df[COLUMNS[-1]])\n    ax.set_xlabel('-'.join(COLUMNS[:-1]))\n    ax.set_ylabel(COLUMNS[-1])\n\n    return analyzed_df, ax [DOC_SEP]     df = pd.DataFrame(data, columns=COLUMNS)\n    analyzed_df = df.groupby(COLUMNS[:-1])[COLUMNS[-1]].nunique().reset_index()\n    ax = sns.distplot(analyzed_df[COLUMNS[-1]])\n\n    return analyzed_df, ax [DOC_SEP]     file_sizes = []\n    for file in sorted(os.listdir(dir_path)):\n        if re.match(pattern, file):\n            file_sizes.append((file, os.path.getsize(os.path.join(dir_path, file))))\n\n    df = pd.DataFrame(file_sizes, columns=['File', 'Size'])\n    return df [DOC_SEP]     # Load data and filter\n    df = pd.read_csv(data)\n    df = df[df['Employee ID'].str.startswith(emp_prefix)]\n\n    # Plot histogram\n    ax = sns.histplot(data=df, x='Age', kde=True)\n\n    return df, ax [DOC_SEP]     emp_salaries = []\n\n    for prefix, num_employees in dict1.items():\n        if not prefix.startswith('EMPXX'):\n            continue\n\n        for _ in range(num_employees):\n            salary = random.randint(*SALARY_RANGE)\n            emp_salaries.append(salary)\n\n    plt.hist(emp_salaries, bins=10, alpha=0.5)\n    plt.title('Salary Distribution in EMPXX Department')\n    plt.xlabel('Salary')\n    plt.ylabel('Number of Employees')\n    return plt.gca() [DOC_SEP]     with open(json_file, 'r') as file:\n        email_data = json.load(file)\n    if not email_data :\n        return pd.DataFrame([], columns = COLUMNS + [\"sum\", \"mean\"]), None\n\n    df = pd.DataFrame(email_data, columns=COLUMNS)\n    df['sum'] = df['list'].apply(np.sum)\n    df['mean'] = df['list'].apply(np.mean)\n\n    ax = df[['sum', 'mean']].plot(kind='bar')\n\n    return df, ax [DOC_SEP]     df = pd.read_csv(csv_file)\n    df['list'] = df['list'].map(ast.literal_eval)\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['std'] = df['list'].apply(np.std)\n    plot = sns.histplot(df['mean'], kde=True)\n    return df, plot [DOC_SEP]     name = None\n    for filename in os.listdir(directory):\n        if filename.endswith('.csv'):\n            if name is None :\n                name = filename\n            else :\n                name = filename if len(filename) > len(name) else name\n    if name is None :\n        return pd.DataFrame({}, columns = ['email', 'list'] + ['sum', 'mean', 'median']), None\n\n    df = pd.read_csv(os.path.join(directory, name))\n    df[\"list\"] = df[\"list\"].map(ast.literal_eval)\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['median'] = df['list'].apply(np.median)\n\n    return df, df[\"median\"].hist() [DOC_SEP]     conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(\"SELECT * FROM EmailData\", conn)\n    df[\"list\"] = df[\"list\"].map(ast.literal_eval)\n    df['sum'] = df['list'].apply(np.sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['var'] = df['list'].apply(np.var)\n\n    ax = df[['sum', 'mean', 'var']].plot(kind='bar')\n    plt.show()\n\n    return df, ax [DOC_SEP]     if not host:\n        raise ValueError(\"Host must be a non-empty string.\")\n\n    try:\n        # Fetch IP address\n        ip_address = socket.gethostbyname(host)\n\n        # Fetch geolocation\n        response = requests.get(f\"https://ipinfo.io/{ip_address}\")\n        response.raise_for_status()\n        geolocation = response.json()\n\n        return {\n            'ip_address': ip_address,\n            'geolocation': geolocation\n        }\n    except (socket.gaierror, requests.HTTPError) as e:\n        raise ConnectionError(f\"Failed to retrieve information for {host}: {e}\") [DOC_SEP]     if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"Input must be a pandas DataFrame\")\n    if not df.empty:\n        raise ValueError(\"Input DataFrame must be empty\")\n    if sales_lower_bound >= sales_upper_bound:\n        raise ValueError(\"sales_lower_bound must be less than sales_upper_bound\")\n\n    if fruits is None:\n        fruits = ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry']\n    if days is None:\n        # Set days to range from January 1, 2024, to January 7, 2024\n        days = [datetime(2024, 1, 1) + timedelta(days=x) for x in range(7)]\n\n    if seed is not None:\n        np.random.seed(seed)\n\n    data = list(itertools.product(fruits, days))\n    sales_data = pd.DataFrame(data, columns=['Fruit', 'Day'])\n    sales_data['Sales'] = np.random.randint(sales_lower_bound, sales_upper_bound, size=len(data))\n\n    result_df = pd.concat([df, sales_data])\n    plot = sns.boxplot(x='Fruit', y='Sales', data=result_df)\n\n    return result_df, plot [DOC_SEP]     session_key = ''.join(random.choices(string.ascii_letters + string.digits, k=20))\n    \n    has_digit = any(char.isdigit() for char in session_key)\n    has_letter = any(char.isalpha() for char in session_key)\n    if not (has_digit and has_letter or len(session_key)!=20):\n        raise ValueError(\"Session key should contain both letters and digits\")\n\n    response = HttpResponse('Session key generated successfully.')\n    response.set_cookie('session_key', session_key, max_age=session_expire_time)\n    return response [DOC_SEP]     try:\n        username = data['username']\n        password = base64.b64decode(data['password']).decode()\n    except (KeyError, UnicodeDecodeError, binascii.Error, ValueError):\n        return HttpResponseBadRequest('Bad Request')\n\n    hashed_password = hashlib.sha256(password.encode()).digest()\n\n    # Dummy authentication logic\n    if username == 'admin' and hashed_password == hashlib.sha256('password'.encode()).digest():\n        return HttpResponse('Login successful.')\n    else:\n        return HttpResponse('Login failed.', status=401) [DOC_SEP]     csv_io = io.StringIO()\n    writer = csv.writer(csv_io)\n    writer.writerow(header)\n    writer.writerows(csv_data)\n    csv_io.seek(0)\n\n    response = FileResponse(csv_io, as_attachment=True, filename='data.csv')\n    response['Content-Type'] = 'text/csv'\n\n    return response [DOC_SEP]     zip_io = io.BytesIO()\n\n    with zipfile.ZipFile(zip_io, 'w') as zip_file:\n        for file_path in file_paths:\n            zip_file.writestr(file_path, 'This is the content of {}.'.format(file_path))\n\n    zip_io.seek(0)  # Reset the file pointer to the start of the stream\n    response = FileResponse(zip_io, as_attachment=True, filename='files.zip')\n    response['Content-Type'] = 'application/zip'\n\n    return response [DOC_SEP] \n    app = Flask(__name__, template_folder=template_folder)\n\n    @app.route('/', methods=['POST'])\n    def handle_post():\n        data = request.get_json()\n        logging.info(json.dumps(data))\n        return render_template('index.html', data=data)\n\n    return app [DOC_SEP]     app = Flask(__name__, template_folder=template_folder)\n    api = Api(app)\n\n    class DataResource(Resource):\n        def get(self):\n            response = requests.get(api_url)\n            data = response.json()\n            return data\n\n    api.add_resource(DataResource, '/data')\n\n    return app [DOC_SEP] \n    app = Flask(__name__, template_folder=template_folder)\n    app.config['SECRET_KEY'] = secret_key\n\n    login_manager.init_app(app)\n\n    class User(UserMixin):\n        def __init__(self, username, password):\n            self.id = username\n            self.password_hash = generate_password_hash(password)\n\n        def check_password(self, password):\n            return check_password_hash(self.password_hash, password)\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = User(form.username.data, form.password.data)\n            login_user(user)\n            return redirect(url_for('protected'))\n\n        return render_template('login.html', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('login'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return 'Logged in as: ' + current_user.id\n\n    # Mock user loader for testing\n    @login_manager.user_loader\n    def load_user(user_id):\n        return User(user_id, 'password')\n\n    return app [DOC_SEP]     app = Flask(__name__, template_folder=template_folder)\n    app.config['MAIL_SERVER'] = smtp_server\n    app.config['MAIL_PORT'] = smtp_port\n    app.config['MAIL_USERNAME'] = smtp_user\n    app.config['MAIL_PASSWORD'] = smtp_password\n    app.config['MAIL_USE_TLS'] = True\n    \n    mail = Mail()\n    mail.init_app(app)\n\n    @app.route('/send_mail')\n    def send_mail():\n        msg = Message('Hello', sender='from@example.com', recipients=['to@example.com'])\n        msg.body = 'Hello Flask message sent from Flask-Mail'\n        mail.send(msg)\n\n        return 'Mail sent!'\n\n    return app [DOC_SEP]     np.random.seed(random_seed)\n    \n    if not products:\n        return pd.DataFrame(columns=[\"Product\", \"Sales\", \"Profit\"])\n\n    if not isinstance(products, list) or not all(isinstance(product, str) for product in products):\n        raise TypeError(\"products must be a list of strings.\")\n    if not isinstance(n_samples, int) or n_samples <= 0:\n        raise ValueError(\"n_samples must be a positive integer.\")\n    if not (isinstance(sales_lower, int) and isinstance(sales_upper, int)) or sales_lower >= sales_upper:\n        raise ValueError(\"sales_lower must be less than sales_upper and both must be integers.\")\n    if not all(isinstance(x, (int, float)) for x in [profit_margin_min, profit_margin_max]) or profit_margin_min >= profit_margin_max:\n        raise ValueError(\"profit_margin_min must be less than profit_margin_max and both must be numeric.\")\n\n    data = []\n    for _ in range(n_samples):\n        product = np.random.choice(products)\n        sales = np.random.randint(sales_lower, sales_upper + 1)\n        profit = sales * np.random.uniform(profit_margin_min, profit_margin_max)\n        data.append([product, sales, profit])\n\n    df = pd.DataFrame(data, columns=[\"Product\", \"Sales\", \"Profit\"])\n    df = df.groupby(\"Product\", as_index=False).sum()\n    df.sort_values(\"Profit\", ascending=False, inplace=True)\n\n    return df [DOC_SEP]     if end_date < start_date:\n        raise ValueError(\"End date must be after start date\")\n\n    np.random.seed(random_seed)\n\n    COLUMNS = [\"Date\", \"Temperature\", \"Humidity\", \"Wind Speed\"]\n    data = []\n    date = start_date\n\n    while date <= end_date:\n        temp = np.random.uniform(-10, 40)\n        humidity = np.random.uniform(20, 100)\n        wind_speed = np.random.uniform(0, 20)\n        data.append([date, temp, humidity, wind_speed])\n        date += timedelta(days=1)\n\n    df = pd.DataFrame(data, columns=COLUMNS)\n    ax = df.plot(x='Date', y=['Temperature', 'Humidity', 'Wind Speed'], title=\"Generated Weather Data\")\n\n    return df, ax [DOC_SEP]     np.random.seed(seed)\n    scores_data = [(student, np.random.randint(0, 100)) for student in students]\n    df = pd.DataFrame(scores_data, columns=[\"Student\", \"Score\"])\n    df.sort_values(\"Score\", inplace=True)\n\n    ax = df.plot(x='Student', y='Score', kind='bar', legend=False)\n    ax.set_ylabel(\"Score\")\n\n    return df, ax [DOC_SEP] \n    seed(random_seed)  # Setting the seed for reproducibility\n    product_ratings = []\n\n    for product in products:\n        rating = choices(ratings, weights, k=1)[0]\n        product_ratings.append([product, rating])\n\n    df = pd.DataFrame(product_ratings, columns=[\"Product\", \"Rating\"])\n    df.sort_values(\"Rating\", ascending=False, inplace=True)\n\n    return df [DOC_SEP]     np.random.seed(seed)\n    data = []\n    date = start_date\n\n    while date <= end_date:\n        sales = np.random.randint(0, 500)\n        data.append([date, sales])\n        date += timedelta(days=1)\n\n    df = pd.DataFrame(data, columns=[\"Date\", \"Sales\"])\n    ax = df.plot(x='Date', y='Sales')\n    ax.set_ylabel(\"Sales\")\n\n    return df, ax [DOC_SEP]     # Copy the data to avoid modifying the original array\n    data_copy = np.copy(data)\n    column_data = data_copy[:, column]\n\n    # Standardize the data to have a mean of 0 and a standard deviation of 1\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(column_data.reshape(-1, 1))\n\n    # Calculate the Z-scores\n    z_scores = np.abs(stats.zscore(standardized_data))\n\n    # Identify the outliers\n    outliers = np.where(z_scores > outlier_z_score)\n    data_without_outliers = np.delete(data_copy, outliers, axis=0)\n\n    # Plot the data before and after the removal of outliers\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.scatter(data_copy[:, 0], data_copy[:, 1])\n    plt.title('Data with Outliers')\n\n    plt.subplot(1, 2, 2)\n    plt.scatter(data_without_outliers[:, 0], data_without_outliers[:, 1])\n    plt.title('Data without Outliers')\n\n    plt.show()\n\n    return data_copy, data_without_outliers, outliers [DOC_SEP]     if not isinstance(k, int) or k < 0:\n        raise ValueError(\"'k' must be a non-negative integer\")\n\n    RADIUS_EARTH_KM = 6371.0  # Radius of the Earth in kilometers\n\n    def calculate_distance(coord1, coord2):\n        # Convert coordinates from degrees to radians\n        lat1, lon1 = math.radians(coord1[0]), math.radians(coord1[1])\n        lat2, lon2 = math.radians(coord2[0]), math.radians(coord2[1])\n\n        # Haversine formula\n        dlat = lat2 - lat1\n        dlon = lon2 - lon1\n        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n\n        return RADIUS_EARTH_KM * c\n\n    distances = np.array([calculate_distance(target, coord) for coord in data.to_numpy()])\n    nearest_indices = distances.argsort()[:k]\n    nearest_neighbors = data.iloc[nearest_indices].values.tolist()\n\n    return nearest_neighbors [DOC_SEP]     if column1 not in data.columns or column2 not in data.columns:\n        raise ValueError(\"Specified columns must exist in the DataFrame\")\n\n    x = data[column1].values\n    y = data[column2].values\n\n    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y, 'o', label='original data')\n    ax.plot(x, intercept + slope*x, 'r', label='fitted line')\n    ax.legend()\n\n    return (slope, intercept, r_value, p_value, std_err), ax [DOC_SEP]     if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input 'data' must be a pandas DataFrame.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' must be an integer greater than 1.\")\n\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(data)\n    centroids = kmeans.cluster_centers_\n\n    fig, ax = plt.subplots()\n    ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels, cmap='viridis', alpha=0.6, label='Data points')\n    ax.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, c='red', label='Centroids')\n    ax.set_xlabel('Feature 1')\n    ax.set_ylabel('Feature 2')\n    ax.set_title('K-Means Clustering')\n    ax.legend()\n\n    return labels, ax [DOC_SEP]     np.random.seed(42)\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n\n    fig, ax = plt.subplots()\n    ax.scatter(transformed_data[:, 0], transformed_data[:, 1])\n\n    return pd.DataFrame(transformed_data, columns=[f'PC{i+1}' for i in range(n_components)]), ax [DOC_SEP]     samples = np.random.normal(mean, std_dev, num_samples)\n    fig, ax = plt.subplots()\n    ax.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n\n    xmin, xmax = ax.get_xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mean, std_dev)\n    ax.plot(x, p, 'k', linewidth=2)\n    title = \"Fit results: mean = %.2f,  std = %.2f\" % (mean, std_dev)\n    ax.set_title(title)\n\n    return samples, fig [DOC_SEP] \n    if categories is None:\n        categories = ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Beauty & Personal Care']\n    if months is None:\n        months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\n    if not isinstance(categories, list) or not categories:\n        raise ValueError(\"Invalid 'categories': must be a non-empty list.\")\n    if not isinstance(months, list) or not months:\n        raise ValueError(\"Invalid 'months': must be a non-empty list.\")\n\n    seed(random_seed)  # Setting the seed for reproducibility\n    sales_data = []\n\n    for month in months:\n        for category in categories:\n            sales = randint(100, 500) + uniform(0, 1)\n            sales_data.append([month, category, sales])\n\n    sales_df = pd.DataFrame(sales_data, columns=['Month', 'Category', 'Sales'])\n    return sales_df [DOC_SEP]     words = []\n\n    with open(csv_file, 'r') as f:\n        reader = csv.reader(f, delimiter=csv_delimiter)\n        for row in reader:\n            words.extend(row)\n\n    word_counter = Counter(words)\n    most_common_words = sorted(word_counter.items(), key=operator.itemgetter(1), reverse=True)\n\n    return most_common_words [DOC_SEP]     sum_log_products = 0\n\n    for r in range(1, len(numbers) + 1):\n        combinations = itertools.combinations(numbers, r)\n        for combination in combinations:\n            product = reduce(lambda x, y: x * y, combination)\n            sum_log_products += math.log(product)\n\n    return sum_log_products [DOC_SEP]     strings = [''.join(random.choices(string.ascii_lowercase, k=string_length)) for _ in range(num_strings)]\n    characters = ''.join(strings)\n    character_counter = Counter(characters)\n    most_common_characters = character_counter.most_common()\n\n    return most_common_characters [DOC_SEP] \n    plt.rc('font', family='Arial')  # Set the global font to Arial.\n    iris = load_iris()\n    iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    iris_df['species'] = iris.target\n\n    # Create a pair plot with the hue set to species.\n    pair_plot = sns.pairplot(iris_df, hue='species', vars=iris.feature_names)\n    pair_plot.fig.suptitle('Iris Dataset Pair Plot', fontsize=16)  # Title for the figure\n    return pair_plot.fig"
}